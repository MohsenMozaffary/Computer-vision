{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69f67b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this serie of the aim is to classify the dogs' breed. The dataset exists in: https://www.kaggle.com/competitions/dog-breed-identification/data\n",
    "# A naive CNN model, a transfer learning model, and concatenation of different transfer learning models are implemented here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127b17d",
   "metadata": {},
   "source": [
    "# Importing dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62052f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from resizeimage import resizeimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f8c76e",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f857194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"directory_to_the_dataset_folder\"\n",
    "train_dir = os.path.join(main_dir, 'train')\n",
    "images_name = os.listdir(train_dir)\n",
    "df = pd.read_csv (os.path.join(main_dir, 'labels.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7afadef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding identical labels\n",
    "breeds = []\n",
    "for breed in df['breed']:\n",
    "    if breed not in breeds:\n",
    "        breeds.append(breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0e3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating label map\n",
    "label_map ={}\n",
    "for i, breed in enumerate(breeds):\n",
    "    label_map[breed] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62605c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating folder for train\n",
    "copied_train_data_dir = 'directory_to_train_data'\n",
    "for breed in breeds:\n",
    "    new_dir = os.path.join(copied_train_data_dir, breed)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8e91e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating folder for validation\n",
    "copied_train_data_dir = 'directory_to_validation_data'\n",
    "for breed in breeds:\n",
    "    new_dir = os.path.join(copied_train_data_dir, breed)\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e029d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of training samples for each class\n",
    "train_samples_each_class = 40\n",
    "# copying train classes in their folders\n",
    "copy_dir = 'train_data_directory'\n",
    "val_dir = 'validation_data_directory'\n",
    "counter = np.zeros((np.array(breeds).shape[0]))\n",
    "for i, breed in  enumerate(df['breed']):\n",
    "    for target_breed in breeds:\n",
    "        if breed == target_breed:\n",
    "            counter[label_map[breed]] += 1\n",
    "            img_name = df['id'][i] + '.jpg'\n",
    "            img_dir = os.path.join(train_dir, img_name)\n",
    "            if counter[label_map[breed]] < train_samples_each_class:\n",
    "                dst = os.path.join(copy_dir, breed)\n",
    "                dst = os.path.join(dst, img_name)\n",
    "                shutil.copy(img_dir, dst)\n",
    "            else:\n",
    "                dst = os.path.join(val_dir, breed)\n",
    "                dst = os.path.join(dst, img_name)\n",
    "                shutil.copy(img_dir, dst)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411b4ab",
   "metadata": {},
   "source": [
    "# 1- Creating naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1853794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# creating a naive CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation = 'relu', input_shape = (150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(64, 3, activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "\n",
    "model.add(layers.Conv2D(128, 3, activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "    \n",
    "    \n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(np.array(breeds).shape[0], activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer = 'rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255) \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(copy_dir,\n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size = (150, 150),\n",
    "                                                        batch_size = 20,\n",
    "                                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a8cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=40,\n",
    "    epochs=80,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27c4d7",
   "metadata": {},
   "source": [
    "# 2- Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b64eb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4680 images belonging to 120 classes.\n",
      "Found 5542 images belonging to 120 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51744)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               26493440  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,925,324\n",
      "Trainable params: 30,888,586\n",
      "Non-trainable params: 36,738\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohsen\\AppData\\Local\\Temp\\ipykernel_17056\\1432202669.py:54: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "40/40 [==============================] - 29s 474ms/step - loss: 4.5143 - acc: 0.1050 - val_loss: 3.3399 - val_acc: 0.3270\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 15s 382ms/step - loss: 3.2540 - acc: 0.2988 - val_loss: 2.1013 - val_acc: 0.5230\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 15s 369ms/step - loss: 2.5515 - acc: 0.4387 - val_loss: 1.6191 - val_acc: 0.6220\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 14s 350ms/step - loss: 2.3404 - acc: 0.4663 - val_loss: 1.1997 - val_acc: 0.7000\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 13s 339ms/step - loss: 1.9680 - acc: 0.5300 - val_loss: 1.1871 - val_acc: 0.6930\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 13s 328ms/step - loss: 1.8015 - acc: 0.5575 - val_loss: 1.1743 - val_acc: 0.7170\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 13s 316ms/step - loss: 1.7214 - acc: 0.5788 - val_loss: 0.9954 - val_acc: 0.7300\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 12s 303ms/step - loss: 1.5232 - acc: 0.6087 - val_loss: 1.0060 - val_acc: 0.7330\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 1.5393 - acc: 0.6062 - val_loss: 0.9592 - val_acc: 0.7580\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 1.5755 - acc: 0.6162 - val_loss: 0.9580 - val_acc: 0.7510\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 1.5503 - acc: 0.6125 - val_loss: 0.9666 - val_acc: 0.7500\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 12s 295ms/step - loss: 1.4006 - acc: 0.6637 - val_loss: 0.9296 - val_acc: 0.7470\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 1.3722 - acc: 0.6488 - val_loss: 1.0162 - val_acc: 0.7230\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 1.4732 - acc: 0.6225 - val_loss: 0.9938 - val_acc: 0.7430\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 11s 277ms/step - loss: 1.4537 - acc: 0.6200 - val_loss: 0.8792 - val_acc: 0.7600\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 1.4670 - acc: 0.6288 - val_loss: 0.8606 - val_acc: 0.7680\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 11s 273ms/step - loss: 1.3712 - acc: 0.6450 - val_loss: 0.9733 - val_acc: 0.7520\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 1.4326 - acc: 0.6125 - val_loss: 0.9247 - val_acc: 0.7440\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 14s 346ms/step - loss: 1.2281 - acc: 0.6762 - val_loss: 0.8769 - val_acc: 0.7750\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 12s 297ms/step - loss: 1.4050 - acc: 0.6400 - val_loss: 0.9438 - val_acc: 0.7660\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 11s 277ms/step - loss: 1.2552 - acc: 0.6475 - val_loss: 0.8874 - val_acc: 0.7670\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 10s 263ms/step - loss: 1.3559 - acc: 0.6237 - val_loss: 0.9259 - val_acc: 0.7360\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 11s 270ms/step - loss: 1.2603 - acc: 0.6600 - val_loss: 0.8953 - val_acc: 0.7580\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 11s 267ms/step - loss: 1.0948 - acc: 0.6875 - val_loss: 0.8942 - val_acc: 0.7630\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 1.1651 - acc: 0.6775 - val_loss: 0.9624 - val_acc: 0.7540\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 1.2518 - acc: 0.6575 - val_loss: 0.9170 - val_acc: 0.7480\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 11s 264ms/step - loss: 1.1817 - acc: 0.6837 - val_loss: 0.9490 - val_acc: 0.7530\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 11s 264ms/step - loss: 1.2315 - acc: 0.6700 - val_loss: 0.9055 - val_acc: 0.7450\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 10s 261ms/step - loss: 1.1137 - acc: 0.6825 - val_loss: 0.9241 - val_acc: 0.7520\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 11s 269ms/step - loss: 1.1677 - acc: 0.6875 - val_loss: 0.8635 - val_acc: 0.7650\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 10s 258ms/step - loss: 1.1152 - acc: 0.7038 - val_loss: 0.9458 - val_acc: 0.7460\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 10s 261ms/step - loss: 1.2068 - acc: 0.6750 - val_loss: 0.9211 - val_acc: 0.7620\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 11s 264ms/step - loss: 1.1446 - acc: 0.6862 - val_loss: 0.8803 - val_acc: 0.7640\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 11s 270ms/step - loss: 1.2170 - acc: 0.6687 - val_loss: 1.0521 - val_acc: 0.7190\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 1.1668 - acc: 0.6875 - val_loss: 0.9487 - val_acc: 0.7550\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 1.1276 - acc: 0.6938 - val_loss: 0.8774 - val_acc: 0.7610\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 1.0760 - acc: 0.7150 - val_loss: 1.0063 - val_acc: 0.7580\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 10s 261ms/step - loss: 1.1589 - acc: 0.6950 - val_loss: 0.9603 - val_acc: 0.7410\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 1.0358 - acc: 0.7150 - val_loss: 0.9121 - val_acc: 0.7690\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 11s 271ms/step - loss: 1.1051 - acc: 0.6850 - val_loss: 1.0144 - val_acc: 0.7440\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 11s 264ms/step - loss: 1.2264 - acc: 0.6900 - val_loss: 0.9587 - val_acc: 0.7500\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 1.0735 - acc: 0.7025 - val_loss: 0.9850 - val_acc: 0.7570\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 10s 261ms/step - loss: 0.9460 - acc: 0.7250 - val_loss: 0.9394 - val_acc: 0.7610\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 11s 273ms/step - loss: 1.0939 - acc: 0.6963 - val_loss: 1.0039 - val_acc: 0.7410\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 12s 311ms/step - loss: 0.9270 - acc: 0.7312 - val_loss: 0.9421 - val_acc: 0.7530\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 13s 317ms/step - loss: 1.0271 - acc: 0.7025 - val_loss: 0.9619 - val_acc: 0.7600\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 13s 315ms/step - loss: 1.1102 - acc: 0.6938 - val_loss: 1.0120 - val_acc: 0.7350\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 13s 314ms/step - loss: 1.0922 - acc: 0.7150 - val_loss: 0.8866 - val_acc: 0.7480\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 13s 316ms/step - loss: 1.0050 - acc: 0.7163 - val_loss: 0.9128 - val_acc: 0.7850\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 13s 322ms/step - loss: 1.0402 - acc: 0.7113 - val_loss: 0.9783 - val_acc: 0.7510\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 13s 319ms/step - loss: 1.0672 - acc: 0.7063 - val_loss: 0.9107 - val_acc: 0.7710\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 0.9761 - acc: 0.7287 - val_loss: 0.9990 - val_acc: 0.7400\n",
      "Epoch 53/80\n",
      "40/40 [==============================] - 11s 267ms/step - loss: 0.9684 - acc: 0.7275 - val_loss: 0.9066 - val_acc: 0.7680\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 10s 260ms/step - loss: 1.0223 - acc: 0.7175 - val_loss: 0.9465 - val_acc: 0.7590\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 1.0057 - acc: 0.7150 - val_loss: 0.9666 - val_acc: 0.7610\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 0.9416 - acc: 0.7262 - val_loss: 0.8591 - val_acc: 0.7640\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 0.9614 - acc: 0.7150 - val_loss: 0.9585 - val_acc: 0.7560\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 1.0688 - acc: 0.6938 - val_loss: 1.0162 - val_acc: 0.7470\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 1.0110 - acc: 0.7287 - val_loss: 0.9325 - val_acc: 0.7620\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 1.0387 - acc: 0.7150 - val_loss: 0.9185 - val_acc: 0.7670\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 11s 267ms/step - loss: 1.0188 - acc: 0.7150 - val_loss: 0.9609 - val_acc: 0.7590\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 11s 266ms/step - loss: 0.8851 - acc: 0.7500 - val_loss: 1.0759 - val_acc: 0.7100\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 10s 263ms/step - loss: 0.9529 - acc: 0.7475 - val_loss: 0.9559 - val_acc: 0.7640\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 10s 260ms/step - loss: 0.9923 - acc: 0.7250 - val_loss: 0.9079 - val_acc: 0.7650\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 11s 267ms/step - loss: 0.9458 - acc: 0.7312 - val_loss: 1.0052 - val_acc: 0.7500\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 10s 262ms/step - loss: 1.0020 - acc: 0.7375 - val_loss: 0.9371 - val_acc: 0.7480\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 0.8911 - acc: 0.7475 - val_loss: 0.9140 - val_acc: 0.7790\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 11s 265ms/step - loss: 0.9004 - acc: 0.7450 - val_loss: 0.9422 - val_acc: 0.7550\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 10s 257ms/step - loss: 0.9805 - acc: 0.7350 - val_loss: 0.9428 - val_acc: 0.7560\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 10s 259ms/step - loss: 0.8660 - acc: 0.7500 - val_loss: 0.8742 - val_acc: 0.7760\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 11s 266ms/step - loss: 0.9433 - acc: 0.7362 - val_loss: 0.8665 - val_acc: 0.7570\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 11s 264ms/step - loss: 0.9036 - acc: 0.7487 - val_loss: 0.8322 - val_acc: 0.7900\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 10s 261ms/step - loss: 0.8617 - acc: 0.7487 - val_loss: 0.9518 - val_acc: 0.7700\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 11s 263ms/step - loss: 0.8537 - acc: 0.7538 - val_loss: 0.9714 - val_acc: 0.7720\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 10s 260ms/step - loss: 0.8332 - acc: 0.7550 - val_loss: 0.8883 - val_acc: 0.7710\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.8894 - acc: 0.7487 - val_loss: 0.9902 - val_acc: 0.7670\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 12s 310ms/step - loss: 0.9092 - acc: 0.7275 - val_loss: 0.9070 - val_acc: 0.7660\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 13s 318ms/step - loss: 0.8530 - acc: 0.7538 - val_loss: 1.0186 - val_acc: 0.7530\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 13s 330ms/step - loss: 0.8936 - acc: 0.7450 - val_loss: 0.9098 - val_acc: 0.7690\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 13s 321ms/step - loss: 0.8764 - acc: 0.7713 - val_loss: 1.1316 - val_acc: 0.7180\n"
     ]
    }
   ],
   "source": [
    "# In this part, the model is created using transfered information from the other existing models.\n",
    "# Some of the models that have better performance of this dataset is imported here:\n",
    "from tensorflow.keras.applications import InceptionResNetV2, Xception, NASNetMobile, MobileNetV2, DenseNet121, DenseNet169\n",
    "# importing libraries\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# using a data generator to preprocess and augment the existing data.\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest') \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(copy_dir,\n",
    "                                                    target_size = (224, 224),\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size = (224, 224),\n",
    "                                                        batch_size = 20,\n",
    "                                                        class_mode = 'categorical')\n",
    "# Selecting a model for the basis of the transfer learning. You can change it to any existing models.\n",
    "Chosen_model = NASNetMobile\n",
    "conv_base = Chosen_model(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                  input_shape = (224, 224, 3))\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(np.array(breeds).shape[0], activation = 'softmax'))\n",
    "model.summary()\n",
    "conv_base.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=40,\n",
    "    epochs=80,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f16b9c",
   "metadata": {},
   "source": [
    "# 3- Contactenating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "226880a2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4680 images belonging to 120 classes.\n",
      "Found 5542 images belonging to 120 classes.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Concatenated (Functional)   (None, 371712)            27898984  \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               190317056 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 218,379,232\n",
      "Trainable params: 218,240,544\n",
      "Non-trainable params: 138,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohsen\\AppData\\Local\\Temp\\ipykernel_17056\\2856454598.py:83: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "40/40 [==============================] - 31s 613ms/step - loss: 4.7704 - acc: 0.0562 - val_loss: 6.5384 - val_acc: 0.0425 - lr: 1.0000e-04\n",
      "Epoch 2/60\n",
      "40/40 [==============================] - 23s 565ms/step - loss: 4.0959 - acc: 0.1250 - val_loss: 3.7409 - val_acc: 0.1675 - lr: 1.0000e-04\n",
      "Epoch 3/60\n",
      "40/40 [==============================] - 23s 571ms/step - loss: 3.5572 - acc: 0.2516 - val_loss: 2.8202 - val_acc: 0.3750 - lr: 1.0000e-04\n",
      "Epoch 4/60\n",
      "40/40 [==============================] - 23s 575ms/step - loss: 3.0785 - acc: 0.3641 - val_loss: 2.2311 - val_acc: 0.4938 - lr: 1.0000e-04\n",
      "Epoch 5/60\n",
      "40/40 [==============================] - 23s 562ms/step - loss: 2.7184 - acc: 0.4281 - val_loss: 2.3346 - val_acc: 0.4613 - lr: 9.9999e-05\n",
      "Epoch 6/60\n",
      "40/40 [==============================] - 23s 580ms/step - loss: 2.5117 - acc: 0.4797 - val_loss: 1.9058 - val_acc: 0.5612 - lr: 9.9999e-05\n",
      "Epoch 7/60\n",
      "40/40 [==============================] - 24s 601ms/step - loss: 2.4336 - acc: 0.4828 - val_loss: 1.5633 - val_acc: 0.6625 - lr: 9.9999e-05\n",
      "Epoch 8/60\n",
      "40/40 [==============================] - 23s 575ms/step - loss: 2.0691 - acc: 0.5938 - val_loss: 1.4794 - val_acc: 0.6513 - lr: 9.9999e-05\n",
      "Epoch 9/60\n",
      "40/40 [==============================] - 24s 595ms/step - loss: 1.8539 - acc: 0.6377 - val_loss: 1.1316 - val_acc: 0.7513 - lr: 9.9999e-05\n",
      "Epoch 10/60\n",
      "40/40 [==============================] - 23s 583ms/step - loss: 1.8180 - acc: 0.6219 - val_loss: 1.2702 - val_acc: 0.7088 - lr: 9.9998e-05\n",
      "Epoch 11/60\n",
      "40/40 [==============================] - 23s 582ms/step - loss: 1.6584 - acc: 0.6828 - val_loss: 0.9631 - val_acc: 0.7775 - lr: 9.9998e-05\n",
      "Epoch 12/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 1.5458 - acc: 0.6891 - val_loss: 0.9864 - val_acc: 0.7725 - lr: 9.9998e-05\n",
      "Epoch 13/60\n",
      "40/40 [==============================] - 24s 596ms/step - loss: 1.4555 - acc: 0.7078 - val_loss: 1.0929 - val_acc: 0.7675 - lr: 9.9998e-05\n",
      "Epoch 14/60\n",
      "40/40 [==============================] - 23s 576ms/step - loss: 1.3942 - acc: 0.7172 - val_loss: 0.7820 - val_acc: 0.8525 - lr: 9.9998e-05\n",
      "Epoch 15/60\n",
      "40/40 [==============================] - 23s 589ms/step - loss: 1.3287 - acc: 0.7312 - val_loss: 0.9621 - val_acc: 0.7887 - lr: 9.9998e-05\n",
      "Epoch 16/60\n",
      "40/40 [==============================] - 24s 592ms/step - loss: 1.2572 - acc: 0.7516 - val_loss: 0.7647 - val_acc: 0.8275 - lr: 9.9998e-05\n",
      "Epoch 17/60\n",
      "40/40 [==============================] - 23s 585ms/step - loss: 1.1423 - acc: 0.7641 - val_loss: 0.7219 - val_acc: 0.8263 - lr: 9.9997e-05\n",
      "Epoch 18/60\n",
      "40/40 [==============================] - 23s 577ms/step - loss: 1.2901 - acc: 0.7250 - val_loss: 0.6966 - val_acc: 0.8275 - lr: 9.9997e-05\n",
      "Epoch 19/60\n",
      "40/40 [==============================] - 23s 576ms/step - loss: 1.1362 - acc: 0.7688 - val_loss: 0.6370 - val_acc: 0.8400 - lr: 9.9997e-05\n",
      "Epoch 20/60\n",
      "40/40 [==============================] - 23s 587ms/step - loss: 0.9687 - acc: 0.8047 - val_loss: 0.6727 - val_acc: 0.8363 - lr: 9.9997e-05\n",
      "Epoch 21/60\n",
      "40/40 [==============================] - 24s 593ms/step - loss: 1.0541 - acc: 0.7734 - val_loss: 0.6569 - val_acc: 0.8375 - lr: 9.9997e-05\n",
      "Epoch 22/60\n",
      "40/40 [==============================] - 23s 576ms/step - loss: 0.9800 - acc: 0.7875 - val_loss: 0.5185 - val_acc: 0.8662 - lr: 9.9996e-05\n",
      "Epoch 23/60\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 1.0244 - acc: 0.7595 - val_loss: 0.7220 - val_acc: 0.8163 - lr: 9.9996e-05\n",
      "Epoch 24/60\n",
      "40/40 [==============================] - 23s 581ms/step - loss: 1.0183 - acc: 0.7953 - val_loss: 0.6117 - val_acc: 0.8375 - lr: 9.9996e-05\n",
      "Epoch 25/60\n",
      "40/40 [==============================] - 23s 582ms/step - loss: 1.0091 - acc: 0.7734 - val_loss: 0.7562 - val_acc: 0.8288 - lr: 9.9996e-05\n",
      "Epoch 26/60\n",
      "40/40 [==============================] - 23s 581ms/step - loss: 1.0378 - acc: 0.7753 - val_loss: 0.5153 - val_acc: 0.8813 - lr: 9.9996e-05\n",
      "Epoch 27/60\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.9910 - acc: 0.7658 - val_loss: 0.6327 - val_acc: 0.8200 - lr: 9.9996e-05\n",
      "Epoch 28/60\n",
      "40/40 [==============================] - 24s 593ms/step - loss: 0.9593 - acc: 0.7785 - val_loss: 0.6560 - val_acc: 0.8263 - lr: 9.9996e-05\n",
      "Epoch 29/60\n",
      "40/40 [==============================] - 23s 576ms/step - loss: 0.8964 - acc: 0.7943 - val_loss: 0.6066 - val_acc: 0.8288 - lr: 9.9995e-05\n",
      "Epoch 30/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 0.8415 - acc: 0.8234 - val_loss: 0.5526 - val_acc: 0.8487 - lr: 9.9995e-05\n",
      "Epoch 31/60\n",
      "40/40 [==============================] - 23s 578ms/step - loss: 0.8557 - acc: 0.8016 - val_loss: 0.5860 - val_acc: 0.8462 - lr: 9.9995e-05\n",
      "Epoch 32/60\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 0.8511 - acc: 0.8141 - val_loss: 0.6918 - val_acc: 0.8225 - lr: 9.9995e-05\n",
      "Epoch 33/60\n",
      "40/40 [==============================] - 23s 589ms/step - loss: 0.7991 - acc: 0.8297 - val_loss: 0.5360 - val_acc: 0.8438 - lr: 9.9995e-05\n",
      "Epoch 34/60\n",
      "40/40 [==============================] - 24s 596ms/step - loss: 0.7483 - acc: 0.8453 - val_loss: 0.5488 - val_acc: 0.8475 - lr: 9.9994e-05\n",
      "Epoch 35/60\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.7214 - acc: 0.8449 - val_loss: 0.4963 - val_acc: 0.8625 - lr: 9.9994e-05\n",
      "Epoch 36/60\n",
      "40/40 [==============================] - 23s 581ms/step - loss: 0.6880 - acc: 0.8576 - val_loss: 0.5082 - val_acc: 0.8450 - lr: 9.9994e-05\n",
      "Epoch 37/60\n",
      "40/40 [==============================] - 23s 580ms/step - loss: 0.6454 - acc: 0.8578 - val_loss: 0.4412 - val_acc: 0.8800 - lr: 9.9994e-05\n",
      "Epoch 38/60\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.6511 - acc: 0.8449 - val_loss: 0.5054 - val_acc: 0.8600 - lr: 9.9994e-05\n",
      "Epoch 39/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 0.6693 - acc: 0.8578 - val_loss: 0.4912 - val_acc: 0.8750 - lr: 9.9994e-05\n",
      "Epoch 40/60\n",
      "40/40 [==============================] - 23s 589ms/step - loss: 0.5986 - acc: 0.8594 - val_loss: 0.4544 - val_acc: 0.8600 - lr: 9.9994e-05\n",
      "Epoch 41/60\n",
      "40/40 [==============================] - 23s 581ms/step - loss: 0.6488 - acc: 0.8594 - val_loss: 0.4597 - val_acc: 0.8737 - lr: 9.9993e-05\n",
      "Epoch 42/60\n",
      "40/40 [==============================] - 23s 587ms/step - loss: 0.6324 - acc: 0.8528 - val_loss: 0.4790 - val_acc: 0.8650 - lr: 9.9993e-05\n",
      "Epoch 43/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 0.5614 - acc: 0.8609 - val_loss: 0.4803 - val_acc: 0.8675 - lr: 9.9993e-05\n",
      "Epoch 44/60\n",
      "40/40 [==============================] - 23s 583ms/step - loss: 0.6193 - acc: 0.8547 - val_loss: 0.4816 - val_acc: 0.8675 - lr: 9.9993e-05\n",
      "Epoch 45/60\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.5927 - acc: 0.8672 - val_loss: 0.4649 - val_acc: 0.8637 - lr: 9.9993e-05\n",
      "Epoch 46/60\n",
      "40/40 [==============================] - 23s 585ms/step - loss: 0.6174 - acc: 0.8609 - val_loss: 0.5766 - val_acc: 0.8138 - lr: 9.9993e-05\n",
      "Epoch 47/60\n",
      "40/40 [==============================] - 23s 587ms/step - loss: 0.6356 - acc: 0.8609 - val_loss: 0.5186 - val_acc: 0.8562 - lr: 9.9992e-05\n",
      "Epoch 48/60\n",
      "40/40 [==============================] - 24s 611ms/step - loss: 0.5997 - acc: 0.8656 - val_loss: 0.5341 - val_acc: 0.8562 - lr: 9.9992e-05\n",
      "Epoch 49/60\n",
      "40/40 [==============================] - 23s 581ms/step - loss: 0.6072 - acc: 0.8594 - val_loss: 0.4046 - val_acc: 0.8925 - lr: 9.9992e-05\n",
      "Epoch 50/60\n",
      "40/40 [==============================] - 23s 582ms/step - loss: 0.5629 - acc: 0.8687 - val_loss: 0.4866 - val_acc: 0.8562 - lr: 9.9992e-05\n",
      "Epoch 51/60\n",
      "40/40 [==============================] - 23s 584ms/step - loss: 0.5758 - acc: 0.8641 - val_loss: 0.4486 - val_acc: 0.8675 - lr: 9.9992e-05\n",
      "Epoch 52/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 0.5952 - acc: 0.8547 - val_loss: 0.4432 - val_acc: 0.8637 - lr: 9.9991e-05\n",
      "Epoch 53/60\n",
      "40/40 [==============================] - 23s 587ms/step - loss: 0.5244 - acc: 0.8766 - val_loss: 0.4216 - val_acc: 0.8825 - lr: 9.9991e-05\n",
      "Epoch 54/60\n",
      "40/40 [==============================] - 23s 585ms/step - loss: 0.4900 - acc: 0.8797 - val_loss: 0.5007 - val_acc: 0.8612 - lr: 9.9991e-05\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 23s 581ms/step - loss: 0.5012 - acc: 0.8781 - val_loss: 0.4785 - val_acc: 0.8587 - lr: 9.9991e-05\n",
      "Epoch 56/60\n",
      "40/40 [==============================] - 23s 584ms/step - loss: 0.5349 - acc: 0.8625 - val_loss: 0.4687 - val_acc: 0.8775 - lr: 9.9991e-05\n",
      "Epoch 57/60\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.5053 - acc: 0.8877 - val_loss: 0.4395 - val_acc: 0.8763 - lr: 9.9991e-05\n",
      "Epoch 58/60\n",
      "40/40 [==============================] - 23s 584ms/step - loss: 0.4557 - acc: 0.8828 - val_loss: 0.4134 - val_acc: 0.8763 - lr: 9.9991e-05\n",
      "Epoch 59/60\n",
      "40/40 [==============================] - 23s 586ms/step - loss: 0.4741 - acc: 0.8875 - val_loss: 0.3960 - val_acc: 0.8788 - lr: 9.9990e-05\n",
      "Epoch 60/60\n",
      "40/40 [==============================] - 23s 577ms/step - loss: 0.5457 - acc: 0.8672 - val_loss: 0.4797 - val_acc: 0.8438 - lr: 9.9990e-05\n"
     ]
    }
   ],
   "source": [
    "# This model concatenates the extracted features from two basis model and classifies based on these two models' features.\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.applications import InceptionResNetV2, Xception, NASNetMobile, MobileNetV2, DenseNet121, DenseNet169\n",
    "import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D,  \\\n",
    "    Dropout, Dense, Input, concatenate,      \\\n",
    "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
    "    Flatten\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest') \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(copy_dir,\n",
    "                                                    target_size = (350, 350),\n",
    "                                                    batch_size = 16,\n",
    "                                                    class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size = (350, 350),\n",
    "                                                        batch_size = 16,\n",
    "                                                        class_mode = 'categorical')\n",
    "\n",
    "# The input is going into two base models.\n",
    "input_layer = Input(shape=(350, 350, 3))\n",
    "\n",
    "x1 = DenseNet121(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                  input_shape = (350, 350, 3))(input_layer)\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "x2 = Xception(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                  input_shape = (350, 350, 3))(input_layer)\n",
    "x2 = Flatten()(x2)\n",
    "# concatenating the features that are extracted from two base models.\n",
    "output = concatenate([x1, x2], axis = 1, name='Mohsen_net')\n",
    "\n",
    "model_new = Model(input_layer, output, name='Concatenated')\n",
    "\n",
    "conv_base = model_new\n",
    "\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dense(np.array(breeds).shape[0], activation = 'softmax'))\n",
    "model.summary()\n",
    "conv_base.trainable = False\n",
    "\n",
    "\n",
    "epochs=60\n",
    "learning_rate = 0.0001\n",
    "decay_rate = learning_rate / epochs\n",
    "momentum = 0.8\n",
    "\n",
    "def exp_decay(epoch):\n",
    "    lrate = learning_rate * np.exp(-decay_rate*epoch)\n",
    "    return lrate\n",
    "\n",
    "lr_rate = LearningRateScheduler(exp_decay)\n",
    "callbacks_list = [lr_rate]\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=40,\n",
    "    callbacks=callbacks_list,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433af2b2",
   "metadata": {},
   "source": [
    "# 4- Fine Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "400db6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4680 images belonging to 120 classes.\n",
      "Found 5542 images belonging to 120 classes.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " NASNet (Functional)         (None, 7, 7, 1056)        4269716   \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 51744)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               26493440  \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 30,925,324\n",
      "Trainable params: 30,888,586\n",
      "Non-trainable params: 36,738\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohsen\\AppData\\Local\\Temp\\ipykernel_17056\\4277022785.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "40/40 [==============================] - 25s 359ms/step - loss: 4.7213 - acc: 0.0913 - val_loss: 3.6209 - val_acc: 0.2770\n",
      "Epoch 2/80\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 3.6081 - acc: 0.2375 - val_loss: 2.2915 - val_acc: 0.4920\n",
      "Epoch 3/80\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 2.7318 - acc: 0.3900 - val_loss: 1.5726 - val_acc: 0.6190\n",
      "Epoch 4/80\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 2.1262 - acc: 0.5063 - val_loss: 1.3839 - val_acc: 0.6420\n",
      "Epoch 5/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 1.8734 - acc: 0.5375 - val_loss: 1.1855 - val_acc: 0.6930\n",
      "Epoch 6/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 1.7879 - acc: 0.5738 - val_loss: 1.3476 - val_acc: 0.6810\n",
      "Epoch 7/80\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 1.6625 - acc: 0.5950 - val_loss: 1.2122 - val_acc: 0.6900\n",
      "Epoch 8/80\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 1.4581 - acc: 0.6363 - val_loss: 1.0570 - val_acc: 0.7050\n",
      "Epoch 9/80\n",
      "40/40 [==============================] - 11s 288ms/step - loss: 1.3672 - acc: 0.6625 - val_loss: 1.1023 - val_acc: 0.7060\n",
      "Epoch 10/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 1.3161 - acc: 0.6800 - val_loss: 1.1086 - val_acc: 0.7010\n",
      "Epoch 11/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 1.3920 - acc: 0.6513 - val_loss: 1.0072 - val_acc: 0.7270\n",
      "Epoch 12/80\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 1.2745 - acc: 0.6587 - val_loss: 1.1965 - val_acc: 0.6970\n",
      "Epoch 13/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 1.2689 - acc: 0.6812 - val_loss: 1.1688 - val_acc: 0.6930\n",
      "Epoch 14/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 1.2132 - acc: 0.6925 - val_loss: 1.2269 - val_acc: 0.6760\n",
      "Epoch 15/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 1.0866 - acc: 0.7125 - val_loss: 1.1684 - val_acc: 0.7050\n",
      "Epoch 16/80\n",
      "40/40 [==============================] - 11s 288ms/step - loss: 1.1420 - acc: 0.7063 - val_loss: 1.2271 - val_acc: 0.6840\n",
      "Epoch 17/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 1.0476 - acc: 0.7150 - val_loss: 1.2122 - val_acc: 0.6860\n",
      "Epoch 18/80\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 1.0731 - acc: 0.7275 - val_loss: 1.0563 - val_acc: 0.7200\n",
      "Epoch 19/80\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 1.1116 - acc: 0.6988 - val_loss: 1.1737 - val_acc: 0.7030\n",
      "Epoch 20/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 1.0675 - acc: 0.7212 - val_loss: 1.1413 - val_acc: 0.7240\n",
      "Epoch 21/80\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 1.0263 - acc: 0.7250 - val_loss: 1.2579 - val_acc: 0.6750\n",
      "Epoch 22/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.9527 - acc: 0.7425 - val_loss: 1.2212 - val_acc: 0.7050\n",
      "Epoch 23/80\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 0.9677 - acc: 0.7387 - val_loss: 1.2055 - val_acc: 0.7100\n",
      "Epoch 24/80\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 0.9030 - acc: 0.7550 - val_loss: 1.1957 - val_acc: 0.7020\n",
      "Epoch 25/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.9644 - acc: 0.7412 - val_loss: 1.0762 - val_acc: 0.7230\n",
      "Epoch 26/80\n",
      "40/40 [==============================] - 12s 296ms/step - loss: 0.9342 - acc: 0.7412 - val_loss: 1.3362 - val_acc: 0.6730\n",
      "Epoch 27/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 0.9175 - acc: 0.7550 - val_loss: 1.3189 - val_acc: 0.6870\n",
      "Epoch 28/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.9073 - acc: 0.7650 - val_loss: 1.3156 - val_acc: 0.6940\n",
      "Epoch 29/80\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 0.9689 - acc: 0.7312 - val_loss: 1.3499 - val_acc: 0.6740\n",
      "Epoch 30/80\n",
      "40/40 [==============================] - 12s 306ms/step - loss: 0.8564 - acc: 0.7538 - val_loss: 1.3218 - val_acc: 0.6800\n",
      "Epoch 31/80\n",
      "40/40 [==============================] - 12s 295ms/step - loss: 0.8327 - acc: 0.7538 - val_loss: 1.2351 - val_acc: 0.6940\n",
      "Epoch 32/80\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 0.7708 - acc: 0.7912 - val_loss: 1.1386 - val_acc: 0.7160\n",
      "Epoch 33/80\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.7114 - acc: 0.7962 - val_loss: 1.2811 - val_acc: 0.7010\n",
      "Epoch 34/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 0.8539 - acc: 0.7713 - val_loss: 1.3762 - val_acc: 0.7000\n",
      "Epoch 35/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.6929 - acc: 0.8263 - val_loss: 1.1737 - val_acc: 0.7290\n",
      "Epoch 36/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 0.6676 - acc: 0.8225 - val_loss: 1.3204 - val_acc: 0.7020\n",
      "Epoch 37/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.7023 - acc: 0.8125 - val_loss: 1.1889 - val_acc: 0.7010\n",
      "Epoch 38/80\n",
      "40/40 [==============================] - 12s 292ms/step - loss: 0.7067 - acc: 0.8100 - val_loss: 1.2831 - val_acc: 0.7070\n",
      "Epoch 39/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.6550 - acc: 0.8062 - val_loss: 1.3711 - val_acc: 0.6980\n",
      "Epoch 40/80\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 0.7317 - acc: 0.8025 - val_loss: 1.1967 - val_acc: 0.7070\n",
      "Epoch 41/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 0.6931 - acc: 0.8050 - val_loss: 1.3094 - val_acc: 0.6820\n",
      "Epoch 42/80\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.6446 - acc: 0.8175 - val_loss: 1.2472 - val_acc: 0.7300\n",
      "Epoch 43/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 0.6338 - acc: 0.8350 - val_loss: 1.4614 - val_acc: 0.6940\n",
      "Epoch 44/80\n",
      "40/40 [==============================] - 12s 299ms/step - loss: 0.6495 - acc: 0.8025 - val_loss: 1.3485 - val_acc: 0.6870\n",
      "Epoch 45/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.6256 - acc: 0.8213 - val_loss: 1.3219 - val_acc: 0.7070\n",
      "Epoch 46/80\n",
      "40/40 [==============================] - 12s 302ms/step - loss: 0.6002 - acc: 0.8313 - val_loss: 1.5210 - val_acc: 0.6650\n",
      "Epoch 47/80\n",
      "40/40 [==============================] - 12s 294ms/step - loss: 0.5897 - acc: 0.8275 - val_loss: 1.5553 - val_acc: 0.6630\n",
      "Epoch 48/80\n",
      "40/40 [==============================] - 12s 291ms/step - loss: 0.6319 - acc: 0.8200 - val_loss: 1.5692 - val_acc: 0.6610\n",
      "Epoch 49/80\n",
      "40/40 [==============================] - 11s 280ms/step - loss: 0.5410 - acc: 0.8562 - val_loss: 1.4575 - val_acc: 0.6960\n",
      "Epoch 50/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 0.5149 - acc: 0.8500 - val_loss: 1.6554 - val_acc: 0.6320\n",
      "Epoch 51/80\n",
      "40/40 [==============================] - 11s 279ms/step - loss: 0.5632 - acc: 0.8425 - val_loss: 1.6678 - val_acc: 0.6510\n",
      "Epoch 52/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.5093 - acc: 0.8562 - val_loss: 1.5022 - val_acc: 0.6730\n",
      "Epoch 53/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.5646 - acc: 0.8475 - val_loss: 1.4791 - val_acc: 0.6690\n",
      "Epoch 54/80\n",
      "40/40 [==============================] - 12s 294ms/step - loss: 0.4994 - acc: 0.8462 - val_loss: 1.4007 - val_acc: 0.7010\n",
      "Epoch 55/80\n",
      "40/40 [==============================] - 12s 290ms/step - loss: 0.5970 - acc: 0.8313 - val_loss: 1.5482 - val_acc: 0.6700\n",
      "Epoch 56/80\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.4569 - acc: 0.8763 - val_loss: 1.4786 - val_acc: 0.6630\n",
      "Epoch 57/80\n",
      "40/40 [==============================] - 11s 281ms/step - loss: 0.5320 - acc: 0.8537 - val_loss: 1.4621 - val_acc: 0.6670\n",
      "Epoch 58/80\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.4904 - acc: 0.8425 - val_loss: 1.5201 - val_acc: 0.6730\n",
      "Epoch 59/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 0.4500 - acc: 0.8838 - val_loss: 1.3963 - val_acc: 0.6990\n",
      "Epoch 60/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.4813 - acc: 0.8413 - val_loss: 1.4661 - val_acc: 0.6800\n",
      "Epoch 61/80\n",
      "40/40 [==============================] - 12s 293ms/step - loss: 0.4367 - acc: 0.8625 - val_loss: 1.3879 - val_acc: 0.6970\n",
      "Epoch 62/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 12s 294ms/step - loss: 0.4415 - acc: 0.8562 - val_loss: 1.6167 - val_acc: 0.6540\n",
      "Epoch 63/80\n",
      "40/40 [==============================] - 12s 289ms/step - loss: 0.4457 - acc: 0.8712 - val_loss: 1.5251 - val_acc: 0.6830\n",
      "Epoch 64/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.4900 - acc: 0.8600 - val_loss: 1.6951 - val_acc: 0.6640\n",
      "Epoch 65/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.5139 - acc: 0.8500 - val_loss: 1.5867 - val_acc: 0.6840\n",
      "Epoch 66/80\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.4624 - acc: 0.8650 - val_loss: 1.6578 - val_acc: 0.6660\n",
      "Epoch 67/80\n",
      "40/40 [==============================] - 11s 278ms/step - loss: 0.4221 - acc: 0.8737 - val_loss: 1.3526 - val_acc: 0.7210\n",
      "Epoch 68/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.3342 - acc: 0.8913 - val_loss: 1.4482 - val_acc: 0.6900\n",
      "Epoch 69/80\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.4346 - acc: 0.8650 - val_loss: 1.4037 - val_acc: 0.7080\n",
      "Epoch 70/80\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.4223 - acc: 0.8813 - val_loss: 1.4409 - val_acc: 0.6960\n",
      "Epoch 71/80\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.4264 - acc: 0.8800 - val_loss: 1.4366 - val_acc: 0.7080\n",
      "Epoch 72/80\n",
      "40/40 [==============================] - 11s 285ms/step - loss: 0.3740 - acc: 0.9000 - val_loss: 1.5408 - val_acc: 0.7010\n",
      "Epoch 73/80\n",
      "40/40 [==============================] - 11s 288ms/step - loss: 0.3672 - acc: 0.8963 - val_loss: 1.4227 - val_acc: 0.7040\n",
      "Epoch 74/80\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.3867 - acc: 0.8900 - val_loss: 1.5788 - val_acc: 0.6880\n",
      "Epoch 75/80\n",
      "40/40 [==============================] - 11s 282ms/step - loss: 0.2871 - acc: 0.9075 - val_loss: 1.4804 - val_acc: 0.7060\n",
      "Epoch 76/80\n",
      "40/40 [==============================] - 12s 288ms/step - loss: 0.3532 - acc: 0.9225 - val_loss: 1.4416 - val_acc: 0.7050\n",
      "Epoch 77/80\n",
      "40/40 [==============================] - 11s 284ms/step - loss: 0.3355 - acc: 0.8988 - val_loss: 1.6177 - val_acc: 0.6690\n",
      "Epoch 78/80\n",
      "40/40 [==============================] - 11s 287ms/step - loss: 0.3837 - acc: 0.8813 - val_loss: 1.7452 - val_acc: 0.6630\n",
      "Epoch 79/80\n",
      "40/40 [==============================] - 11s 286ms/step - loss: 0.3964 - acc: 0.8875 - val_loss: 1.6344 - val_acc: 0.6850\n",
      "Epoch 80/80\n",
      "40/40 [==============================] - 11s 283ms/step - loss: 0.3794 - acc: 0.8850 - val_loss: 1.5406 - val_acc: 0.6920\n"
     ]
    }
   ],
   "source": [
    "# Some part of the base model for transfer learning is going to be trained with our dataset.\n",
    "# The first layers are still freezed, but the last layers of the base model is trainable to be fit to the new dataset.\n",
    "# importing libraries\n",
    "from tensorflow.keras.applications import InceptionResNetV2, Xception, NASNetMobile, MobileNetV2, DenseNet121, DenseNet169\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    fill_mode = 'nearest') \n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(copy_dir,\n",
    "                                                    target_size = (224, 224),\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir,\n",
    "                                                        target_size = (224, 224),\n",
    "                                                        batch_size = 20,\n",
    "                                                        class_mode = 'categorical')\n",
    "conv_base = NASNetMobile(weights = 'imagenet',\n",
    "                  include_top = False,\n",
    "                  input_shape = (224, 224, 3))\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(layers.Dense(256, activation = 'relu'))\n",
    "model.add(layers.Dense(np.array(breeds).shape[0], activation = 'softmax'))\n",
    "model.summary()\n",
    "# creating a basis that has freezed starting layers, and trainable last layers of the base convolutional model.\n",
    "conv_base.trainable = True\n",
    "being_trainable = False\n",
    "for layers_t in conv_base.layers:\n",
    "    if layers_t.name == 'adjust_conv_projection_8' :\n",
    "        being_trainable = True\n",
    "    layers_t.trainable = being_trainable\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(0.0001)\n",
    "\n",
    "\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['acc'])\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=40,\n",
    "    epochs=80,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breed",
   "language": "python",
   "name": "breed"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
