{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b90d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is using CNN for denoising image data. MNIST dataset is used for this task.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The preprocessing step. Normalizes the images. If noise is True, it will add noise to the images with the defined noise factor.\n",
    "def preprocessing(data, noise_factor = 0.1, noise = False):\n",
    "    data_normalized = np.expand_dims(data / 255.0, axis = -1)\n",
    "    if noise:\n",
    "        data_normalized = data_normalized + noise_factor * np.random.normal(\n",
    "        loc = 0, scale = 1, size = data_normalized.shape)\n",
    "    data_normalized = np.clip(data_normalized, 0.0, 1.0)\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eac172f",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ed530e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train, _), (test, _) = tf.keras.datasets.mnist.load_data()\n",
    "train_data = preprocessing(train)\n",
    "test_data = preprocessing(test)\n",
    "train_data_noisy = preprocessing(train, noise_factor = 0.3, noise = True)\n",
    "test_data_noisy = preprocessing(test, noise_factor = 0.3, noise = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2575ab8",
   "metadata": {},
   "source": [
    "# Creating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47b5a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating encoder and decord to get the same size data in the end.\n",
    "#encoder:\n",
    "x_input = tf.keras.layers.Input(shape = train_data[0].shape)\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation = \"relu\", padding = \"same\")(x_input)\n",
    "x = tf.keras.layers.MaxPooling2D(2, padding = \"same\")(x)\n",
    "x = tf.keras.layers.Conv2D(32, 3, activation = \"relu\", padding = \"same\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(2, padding = \"same\")(x)\n",
    "\n",
    "# Decoder:\n",
    "x = tf.keras.layers.Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = \"same\")(x)\n",
    "x = tf.keras.layers.Conv2DTranspose(32, 3, strides = 2, activation = \"relu\", padding = \"same\")(x)\n",
    "output = tf.keras.layers.Conv2D(1, 3, activation = \"sigmoid\", padding = \"same\")(x)\n",
    "\n",
    "# Creating model:\n",
    "noise_cancellation_model = tf.keras.Model(x_input, output)\n",
    "noise_cancellation_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ddfd9",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3e53c0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1687 - val_loss: 0.0932\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0902 - val_loss: 0.0867\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0863 - val_loss: 0.0844\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0845 - val_loss: 0.0830\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0833 - val_loss: 0.0823\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0825 - val_loss: 0.0817\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0819 - val_loss: 0.0810\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0814 - val_loss: 0.0807\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0810 - val_loss: 0.0803\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0807 - val_loss: 0.0800\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0804 - val_loss: 0.0796\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0801 - val_loss: 0.0795\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0799 - val_loss: 0.0793\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0797 - val_loss: 0.0793\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0795 - val_loss: 0.0790\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0793 - val_loss: 0.0790\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0792 - val_loss: 0.0786\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0790 - val_loss: 0.0786\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0789 - val_loss: 0.0785\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0788 - val_loss: 0.0783\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0787 - val_loss: 0.0785\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0785 - val_loss: 0.0780\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0785 - val_loss: 0.0781\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0784 - val_loss: 0.0779\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0783 - val_loss: 0.0779\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0782 - val_loss: 0.0777\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0781 - val_loss: 0.0777\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0781 - val_loss: 0.0775\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0780 - val_loss: 0.0775\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0779 - val_loss: 0.0775\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0779 - val_loss: 0.0775\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0778 - val_loss: 0.0774\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0778 - val_loss: 0.0775\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0778 - val_loss: 0.0773\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0777 - val_loss: 0.0773\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0776 - val_loss: 0.0775\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0776 - val_loss: 0.0772\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0776 - val_loss: 0.0772\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0775 - val_loss: 0.0772\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0775 - val_loss: 0.0772\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0775 - val_loss: 0.0771\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0774 - val_loss: 0.0771\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0774 - val_loss: 0.0770\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0774 - val_loss: 0.0770\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0773 - val_loss: 0.0770\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0773 - val_loss: 0.0769\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0773 - val_loss: 0.0769\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0772 - val_loss: 0.0769\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0772 - val_loss: 0.0772\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0772 - val_loss: 0.0769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25a01b79ee0>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The training data is the created noisy images, and the target is the image before adding noise.\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "noise_cancellation_model.fit(train_data_noisy,\n",
    "                            train_data,\n",
    "                            epochs = epochs,\n",
    "                            batch_size = batch_size,\n",
    "                            shuffle = True,\n",
    "                            validation_data = (test_data_noisy, test_data) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25caedcd",
   "metadata": {},
   "source": [
    "# Plotting images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37581ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot(2, 2, 1)\n",
    "plt.imshow(predictions[0].reshape(28, 28))\n",
    "plt.gray()\n",
    "ax = plt.subplot(2, 2, 2)\n",
    "plt.imshow(test_data_noisy[0].reshape(28, 28))\n",
    "plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465091d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ALL",
   "language": "python",
   "name": "all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
